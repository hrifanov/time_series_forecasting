{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173fd64-40ef-4e71-9b17-7715570b9cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_frequencies_conventions = {\n",
    "    5: '5T', \n",
    "    15: '15T'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269933fe-23c6-4fbc-8cad-240b7b948b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_data(path, freq):\n",
    "    stock = pd.read_csv(path, header=0, sep=';', parse_dates=[0])\n",
    "    \n",
    "    stock.rename(columns={ stock.columns[0]: \"datetime\" }, inplace=True)\n",
    "    \n",
    "    #stock['after_hours'] = (stock['datetime'].dt.hour >= 16).astype('float32')\n",
    "    #stock['pre_market'] = ((stock['datetime'].dt.hour == 8) | ((stock['datetime'].dt.hour == 9) & (stock['datetime'].dt.minute <= 30))).astype('float32')\n",
    "    \n",
    "    stock['is_open'] = ((stock['datetime'].dt.hour >= 9) & (stock['datetime'].dt.minute == 30)).astype('float32')\n",
    "    stock['is_close'] = ((stock['datetime'].dt.hour == 15) & (stock['datetime'].dt.minute == (60-freq))).astype('float32')\n",
    "\n",
    "    \n",
    "    sma_1_hours = 2\n",
    "    sma_2_hours = 8\n",
    "    \n",
    "    stock[f'sma_{sma_1_hours}h'] = stock['close'].rolling(window=int(sma_1_hours*60/freq)).mean()\n",
    "    stock[f'sma_{sma_2_hours}h'] = stock['close'].rolling(window=int(sma_2_hours*60/freq)).mean()\n",
    "    \n",
    "    stock['points_from_start'] = stock.index\n",
    "    \n",
    "    float64_cols = stock.select_dtypes(include='float64').columns\n",
    "    stock[float64_cols] = stock[float64_cols].astype('float32')\n",
    "    \n",
    "    stock = stock.interpolate(method=\"ffill\")\n",
    "    stock = stock.interpolate(method=\"bfill\")\n",
    "    \n",
    "    assert stock.isna().sum().sum() == 0\n",
    "\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8f1e4d-4b79-42df-9e0b-4e73f569f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(stock):\n",
    "    y = stock[['close', 'points_from_start']]\n",
    "    X = stock[['points_from_start', 'close', 'open', 'low', 'high', 'vol', 'spread', 'sma_2h', 'sma_8h', 'is_open', 'is_close']]\n",
    "    \n",
    "    assert y.isna().sum().sum()    ==    0\n",
    "    assert X.isna().sum().sum()    ==    0\n",
    "    \n",
    "    return { \"X\": X, \"y\": y }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16234fda-24c8-463a-9e73-d513c89286d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    SPLIT = 0.8\n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, train_size=SPLIT, shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, train_size=0.5, shuffle=False)\n",
    "    \n",
    "    assert X_val.isna().sum().sum()     ==    0\n",
    "    assert X_test.isna().sum().sum()    ==    0\n",
    "    assert X_train.isna().sum().sum()   ==    0\n",
    "    assert y_val.isna().sum().sum()     ==    0\n",
    "    assert y_test.isna().sum().sum()    ==    0\n",
    "    assert y_train.isna().sum().sum()   ==    0\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_val\": X_val,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_test\": y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc24e0-49ac-4924-a7c3-922b3ae583ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_splits_to_time_series(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "\n",
    "    ts_y_train = TimeSeries.from_dataframe(y_train, time_col='points_from_start')\n",
    "    ts_X_train = TimeSeries.from_dataframe(X_train, time_col='points_from_start')\n",
    "\n",
    "    ts_y_val = TimeSeries.from_dataframe(y_val, time_col='points_from_start')\n",
    "    ts_X_val = TimeSeries.from_dataframe(X_val, time_col='points_from_start')\n",
    "\n",
    "    ts_y_test = TimeSeries.from_dataframe(y_test, time_col='points_from_start')\n",
    "    ts_X_test = TimeSeries.from_dataframe(X_test, time_col='points_from_start')\n",
    "\n",
    "    return {\n",
    "        \"ts_X_train\": ts_X_train,\n",
    "        \"ts_X_val\": ts_X_val,\n",
    "        \"ts_X_test\": ts_X_test,\n",
    "        \"ts_y_train\": ts_y_train,\n",
    "        \"ts_y_val\": ts_y_val,\n",
    "        \"ts_y_test\": ts_y_test\n",
    "    }\n",
    "\n",
    "\n",
    "def transform_to_time_series(X, y):\n",
    "    ts_X_full = TimeSeries.from_dataframe(X,time_col='points_from_start')\n",
    "    ts_y_full = TimeSeries.from_dataframe(y,time_col='points_from_start')\n",
    "\n",
    "    return { \"ts_X_full\": ts_X_full, \"ts_y_full\": ts_y_full }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8125be92-a4cf-43cf-832e-75d7db3fbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_splits_data(ts_X_train, ts_X_val, ts_X_test, ts_y_train, ts_y_val, ts_y_test):\n",
    "    scaler_X = Scaler()\n",
    "    scaler_y = Scaler()\n",
    "\n",
    "    scaled_X_train = scaler_X.fit_transform(ts_X_train)\n",
    "    scaled_X_val = scaler_X.transform(ts_X_val)\n",
    "    scaled_X_test = scaler_X.transform(ts_X_test)\n",
    "\n",
    "    scaled_y_train = scaler_y.fit_transform(ts_y_train)\n",
    "    scaled_y_val = scaler_y.transform(ts_y_val)\n",
    "    scaled_y_test = scaler_y.transform(ts_y_test)\n",
    "\n",
    "    return {\n",
    "        \"scaled_X_train\": scaled_X_train.astype('float32'),\n",
    "        \"scaled_X_val\": scaled_X_val.astype('float32'),\n",
    "        \"scaled_X_test\": scaled_X_test.astype('float32'),\n",
    "        \"scaled_y_train\": scaled_y_train.astype('float32'),\n",
    "        \"scaled_y_val\": scaled_y_val.astype('float32'),\n",
    "        \"scaled_y_test\": scaled_y_test.astype('float32'),\n",
    "        \"scaler_X\": scaler_X,\n",
    "        \"scaler_y\": scaler_y\n",
    "    }\n",
    "\n",
    "def scale_full_data(ts_X_full, ts_y_full, scaler_X, scaler_y):\n",
    "    scaled_X_full = scaler_X.fit_transform(ts_X_full).astype('float32')\n",
    "    scaled_y_full = scaler_y.fit_transform(ts_y_full).astype('float32')\n",
    "\n",
    "    return { \"scaled_X_full\": scaled_X_full, \"scaled_y_full\": scaled_y_full }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c84fb1-2864-4dce-8c1d-975ad95ce22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP (Python 3.11)",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

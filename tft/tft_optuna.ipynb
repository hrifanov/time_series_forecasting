{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d772c59-ca2c-4502-8579-0fdbccf21bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import missingno as mno\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import TFTModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.datasets import AirPassengersDataset\n",
    "from darts.metrics import smape\n",
    "from darts.models import TCNModel\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "\n",
    "import torch\n",
    "from torch.nn import HuberLoss\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.precision\",2)\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402229aa-f9fb-4def-9724-cb8274c2190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ebb1f-725e-4de6-90b5-40ecd5ac516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad6b0c-03b0-454a-9767-dea4b7e10467",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    accelerator = 'mps'\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "    accelerator = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1553f9-3ce7-483e-8206-3f18781938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_INT = 5\n",
    "\n",
    "FREQ_CONVENTION = minute_frequencies_conventions[FREQ_INT]\n",
    "\n",
    "N_TRIALS = 100\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509ddde-b2ac-470d-b20a-bba214799854",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_ticker = ['NVDA']\n",
    "\n",
    "stocks_full = []\n",
    "\n",
    "for ticker in stock_ticker:\n",
    "\n",
    "    stock = load_stock_data(f'../data/resampled_data/{FREQ_CONVENTION}/{ticker}_resampled_{FREQ_CONVENTION}.csv', FREQ_INT)\n",
    "\n",
    "\n",
    "    X_y_df = separate(stock)\n",
    "    splits = split_data(**X_y_df)\n",
    "\n",
    "    ts_splits = transform_splits_to_time_series(**splits)\n",
    "\n",
    "    ts_full = transform_to_time_series(**X_y_df)\n",
    "\n",
    "    scaled_splits_data = scale_splits_data(**ts_splits)\n",
    "\n",
    "    scaled_full_data = scale_full_data(ts_full['ts_X_full'], ts_full['ts_y_full'], scaled_splits_data['scaler_X'], scaled_splits_data['scaler_y'])\n",
    "\n",
    "    stocks_full.append({\n",
    "        \"ticker\": ticker,\n",
    "        \"stock\": stock,\n",
    "        \"splits\": splits,\n",
    "        \"ts_splits\": ts_splits,\n",
    "        \"ts_full\": ts_full,\n",
    "        \"scaled_splits_data\": scaled_splits_data,\n",
    "        \"scaled_full_data\": scaled_full_data\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde152b6-bcac-4d90-b607-3e29effcb2e4",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdbd31-d96e-45ea-83e3-c59c85740fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size     =    64\n",
    "    n_epochs       =    5\n",
    "\n",
    "    out_len = 1\n",
    "    nr_epochs_val_period = 1\n",
    "    valwait = 1        \n",
    "\n",
    "\n",
    "    # Other hyperparameters\n",
    "    in_len = trial.suggest_int(\"output_chunk_length\", 40, 400, step=10)\n",
    "    hidden_layers = trial.suggest_int(\"hidden_layers\", 8, 32, step=8)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 3, step=1)\n",
    "    attention_heads = trial.suggest_int(\"attention_heads\", 2, 8, step=2)\n",
    "    hidden_continuous_size = trial.suggest_int(\"hidden_continuous_size\", 4, 16, step=4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-3, log=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # callbacks\n",
    "    pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=1e-4, patience=3, verbose=True)\n",
    "\n",
    "    callbacks = [pruner, early_stopper]\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "        \"accelerator\": \"cpu\", \n",
    "        \"devices\": 1,\n",
    "        \"callbacks\": callbacks,\n",
    "        'log_every_n_steps': 10\n",
    "    }\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    model = TFTModel(\n",
    "        model_name=\"tft_model\",\n",
    "        n_epochs=n_epochs,\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=hidden_layers,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=attention_heads,\n",
    "        hidden_continuous_size=hidden_continuous_size,\n",
    "        batch_size=batch_size,\n",
    "        dropout=dropout,\n",
    "        nr_epochs_val_period=valwait,\n",
    "        #likelihood=QuantileRegression(QUANTILES),\n",
    "        optimizer_kwargs={\"lr\": 1e-3},\n",
    "        loss_fn=MSELoss(),\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        add_relative_index=True,\n",
    "        force_reset=True,\n",
    "        save_checkpoints=True\n",
    "    )\n",
    "    \n",
    "    nvda = next((stock for stock in stocks_full if stock['ticker'] == 'NVDA'), None)\n",
    "\n",
    "    \n",
    "    scaled_splits_data      =    nvda['scaled_splits_data']\n",
    "    scaled_full_data        =    nvda['scaled_full_data']\n",
    "    ts_splits               =    nvda['ts_splits']\n",
    "\n",
    "    model.fit(\n",
    "      series                =    scaled_splits_data['scaled_y_train'],\n",
    "      past_covariates       =    scaled_splits_data['scaled_X_train'],\n",
    "      val_series            =    scaled_splits_data['scaled_y_val'],\n",
    "      val_past_covariates   =    scaled_splits_data['scaled_X_val'],\n",
    "      verbose               =    False\n",
    "    )\n",
    "\n",
    "    model = TFTModel.load_from_checkpoint(\"tft_model\")\n",
    "    \n",
    "    predictions = model.predict(\n",
    "        n=len(scaled_splits_data['scaled_X_test']),\n",
    "        series=scaled_splits_data['scaled_y_val'],\n",
    "        past_covariates=scaled_full_data['scaled_X_full'],\n",
    "        num_samples=1,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    \n",
    "    predictions_unscaled = scaled_splits_data['scaler_y'].inverse_transform(predictions)\n",
    "    \n",
    "        \n",
    "    smapes = smape(predictions_unscaled, ts_splits['ts_y_test'])\n",
    "    smape_test = np.mean(smapes)\n",
    "\n",
    "    return smape_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa41ef9-b62e-4793-bb00-45781fb5e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_callback(study=None, trial=None):\n",
    "    print('===========================================================================================')\n",
    "    print(f'Current value: {trial.value}, Current params: {trial.params}')\n",
    "    print(f'Best study: {study.best_trial.number}: Best value: {study.best_value}, Best params: {study.best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9151d-9163-4f66-8d6d-f117f7bb0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfe6da-bc94-4ed6-b84e-8b85273807d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff80e5-7c7a-4423-bb48-30faa38a4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea19e15-4e21-4518-8079-612de03680ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8766c-911a-47da-9213-c716a1ebd448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP (Python 3.11)",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
